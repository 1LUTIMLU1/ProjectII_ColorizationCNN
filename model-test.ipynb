{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "# For our model\n",
    "import torchvision.models as convels\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# For utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "from sys import platform\n",
    "from itertools import combinations\n",
    "import torchvision.transforms as T\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(folder):\n",
    "    files = glob.glob(folder)\n",
    "    data =[]\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        data.append(image)\n",
    "    return data\n",
    "\n",
    "\n",
    "def group(data, album_length):\n",
    "    #group into chunks of three because of three sets of images in LAB color space\n",
    "    for i in range (0, album_length, 3):\n",
    "        yield image_data[i:i+3]\n",
    "\n",
    "\n",
    "class SplitLab(object):\n",
    "    \"\"\"Splits tensor LAB image to L and ab channels.\"\"\"\n",
    "    def __call__(self, image):\n",
    "        L  = image[:1,:,:]\n",
    "        ab = image[1:,:,:]\n",
    "        return (L, ab)\n",
    "    \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "       Custom dataset for LAB image preprocessing for colorization\n",
    "    \"\"\"\n",
    "    def __init__(self, images):\n",
    "       \"\"\"\n",
    "       images: array of lab images [idx, h, w, channels],\n",
    "       where for channels 0 = L, 1 = a, 2 = b.\n",
    "       \"\"\"\n",
    "       self.images = images\n",
    "       self.composed = T.Compose([T.ToPILImage(),T.ToTensor(),SplitLab()])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "      \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        returns L, ab mean, and ab for visualization\n",
    "        \"\"\"\n",
    "        image = self.images[idx, :, :, :]\n",
    "        L, ab = self.composed(image)\n",
    "\n",
    "        ab_mean = torch.mean(ab, dim=[1, 2])\n",
    "\n",
    "        sample = {'L': L, 'ab': ab, 'ab_mean': ab_mean}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getcwd() \n",
    "#change this parameter depending on which album you want\n",
    "target_album = 'LAB_TEST_FACES'\n",
    "batch_size = 32\n",
    "\n",
    "# load in data and split into test and train sets\n",
    "image_data = np.asarray(load(home_dir + '/' + target_album + '/' + '*.jpg'))\n",
    "train_images, test_images = train_test_split(image_data, test_size = 0.1, random_state=42)\n",
    "\n",
    "# dataset and dataloader to prepare images for training\n",
    "train_dataset = ImageDataset(train_images)\n",
    "test_dataset = ImageDataset(test_images)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2250\n"
     ]
    }
   ],
   "source": [
    "print(len(image_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# select GPU / CPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrominanceReg(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv3): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv4): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv5): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv6): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (conv7): Sequential(\n",
      "    (0): Conv2d(1, 1, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (1): ReLU()\n",
      "  )\n",
      "  (out): Sequential(\n",
      "    (0): Linear(in_features=1, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ChrominanceReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChrominanceReg, self).__init__()\n",
    "\n",
    "        #128x128\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=2), # 128\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #64x64\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=2), # 64\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #32x32\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=2), # 32\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #16x16\n",
    "        self.conv4 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=2), # 16\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #8x8\n",
    "        self.conv5 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=2), # 8\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #4x4\n",
    "        self.conv6 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=3, stride=2), # 4\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        #2x2\n",
    "        self.conv7 = nn.Sequential(\n",
    "            nn.Conv2d(1, 1, kernel_size=2, stride=2), # 2\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.out = nn.Sequential(                     #1\n",
    "            nn.Linear(1, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = self.conv7(x)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "\n",
    "regressor = ChrominanceReg().to(device)\n",
    "print(regressor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Training loss: 0.08002290112199262\n",
      "\n",
      "Validation Loss =  tensor(0.0062, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hkirkland\\.conda\\envs\\ML\\lib\\site-packages\\torch\\nn\\modules\\loss.py:520: UserWarning: Using a target size (torch.Size([1, 2])) that is different to the input size (torch.Size([2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training loss: 0.009181656711007236\n",
      "Epoch 2 - Training loss: 0.009003997140098363\n",
      "Epoch 3 - Training loss: 0.009073038643691689\n",
      "Epoch 4 - Training loss: 0.009011852380353957\n",
      "\n",
      "Validation Loss =  tensor(0.0194, device='cuda:0')\n",
      "Epoch 5 - Training loss: 0.009069425439520273\n",
      "Epoch 6 - Training loss: 0.009054453672433738\n",
      "Epoch 7 - Training loss: 0.009016628820972983\n",
      "Epoch 8 - Training loss: 0.009059438918484375\n",
      "\n",
      "Validation Loss =  tensor(0.0194, device='cuda:0')\n",
      "Epoch 9 - Training loss: 0.00904452920804033\n",
      "Epoch 10 - Training loss: 0.009023499238537624\n",
      "Epoch 11 - Training loss: 0.00900546721095452\n",
      "Epoch 12 - Training loss: 0.009097065667447168\n",
      "\n",
      "Validation Loss =  tensor(0.0025, device='cuda:0')\n",
      "Epoch 13 - Training loss: 0.009261356884962879\n",
      "Epoch 14 - Training loss: 0.008988868874439504\n",
      "Epoch 15 - Training loss: 0.009243179112672806\n",
      "Epoch 16 - Training loss: 0.009056861184944864\n",
      "\n",
      "Validation Loss =  tensor(0.0061, device='cuda:0')\n",
      "Epoch 17 - Training loss: 0.009162025795376394\n",
      "Epoch 18 - Training loss: 0.00909796757332515\n",
      "Epoch 19 - Training loss: 0.009044919410371222\n",
      "Epoch 20 - Training loss: 0.009107057907385752\n",
      "\n",
      "Validation Loss =  tensor(0.0036, device='cuda:0')\n",
      "Epoch 21 - Training loss: 0.009119963571720291\n",
      "Epoch 22 - Training loss: 0.00905671560758492\n",
      "Epoch 23 - Training loss: 0.009108421261771582\n",
      "Epoch 24 - Training loss: 0.009163666094536893\n",
      "\n",
      "Validation Loss =  tensor(0.0268, device='cuda:0')\n",
      "Epoch 25 - Training loss: 0.009078745017177425\n",
      "Epoch 26 - Training loss: 0.009090690036828164\n",
      "Epoch 27 - Training loss: 0.009030809582327493\n",
      "Epoch 28 - Training loss: 0.009008108856505714\n",
      "\n",
      "Validation Loss =  tensor(0.0020, device='cuda:0')\n",
      "Epoch 29 - Training loss: 0.009156982283457182\n",
      "Epoch 30 - Training loss: 0.009051561850355938\n",
      "Epoch 31 - Training loss: 0.009070964682905469\n",
      "Epoch 32 - Training loss: 0.00907200424990151\n",
      "\n",
      "Validation Loss =  tensor(0.0695, device='cuda:0')\n",
      "Epoch 33 - Training loss: 0.009104461947572418\n",
      "Epoch 34 - Training loss: 0.009045489954587538\n",
      "Epoch 35 - Training loss: 0.00901546894601779\n",
      "Epoch 36 - Training loss: 0.009069981642824132\n",
      "\n",
      "Validation Loss =  tensor(0.0084, device='cuda:0')\n",
      "Epoch 37 - Training loss: 0.009292166629165877\n",
      "Epoch 38 - Training loss: 0.00906002980627818\n",
      "Epoch 39 - Training loss: 0.009138175439147744\n",
      "Epoch 40 - Training loss: 0.009200525277265115\n",
      "\n",
      "Validation Loss =  tensor(0.0491, device='cuda:0')\n",
      "Epoch 41 - Training loss: 0.009154090628726408\n",
      "Epoch 42 - Training loss: 0.009071595217392314\n",
      "Epoch 43 - Training loss: 0.009046909741300624\n",
      "Epoch 44 - Training loss: 0.009192705980240135\n",
      "\n",
      "Validation Loss =  tensor(0.0804, device='cuda:0')\n",
      "Epoch 45 - Training loss: 0.009089265968214022\n",
      "Epoch 46 - Training loss: 0.009053000670974143\n",
      "Epoch 47 - Training loss: 0.009159361667116173\n",
      "Epoch 48 - Training loss: 0.009085352183319628\n",
      "\n",
      "Validation Loss =  tensor(0.0036, device='cuda:0')\n",
      "Epoch 49 - Training loss: 0.00910312776977662\n",
      "\n",
      "Training Finished. \n",
      "Training Time (in minutes) = 0.7321385900179546\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "lr = 0.01\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(regressor.parameters(), lr)\n",
    "\n",
    "regressor.train()\n",
    "\n",
    "time0 = time()\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        # get data\n",
    "        L = data['L']\n",
    "        ab_mean = data['ab_mean']\n",
    "\n",
    "        # send to device\n",
    "        L = L.to(device)\n",
    "        ab_mean = ab_mean.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = regressor(L).squeeze()\n",
    "        loss = loss_fn(outputs, ab_mean)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(train_loader)))\n",
    "\n",
    "    if epoch % 4 == 0:\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            regressor.eval()\n",
    "            for data in test_loader:\n",
    "                val_outputs = regressor(data['L'].to(device))\n",
    "                val_loss = loss_fn(val_outputs.squeeze(), data['ab_mean'].to(device))\n",
    "\n",
    "        print(\"\\nValidation Loss = \", (val_loss))\n",
    "print(\"\\nTraining Finished. \\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    regressor.eval()\n",
    "    for data in test_loader:\n",
    "        true.extend(data['ab_mean'].numpy())\n",
    "        outputs = regressor(data['L'].to(device))\n",
    "        pred.extend(outputs.cpu().squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\HKIRKL~1\\AppData\\Local\\Temp/ipykernel_11896/1589215895.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrue_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\hkirkland\\.conda\\envs\\ML\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[0mshapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'all input arrays must have the same shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[0mresult_ndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "pred_np = np.stack(pred)\n",
    "true_np = np.stack(true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12347ee61ea2ffef8bdd924564b209dba478b26ce284a1f8bfda94c61015ebbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
