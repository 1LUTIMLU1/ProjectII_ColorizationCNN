{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "# For our model\n",
    "import torchvision.models as models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# For utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import normalize\n",
    "from sys import platform\n",
    "from itertools import combinations\n",
    "import torchvision.transforms as T\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(folder):\n",
    "    files = glob.glob(folder)\n",
    "    data =[]\n",
    "    for f in files:\n",
    "        image = cv2.imread(f)\n",
    "        data.append(image)\n",
    "    return data\n",
    "\n",
    "\n",
    "def group(data, album_length):\n",
    "    #group into chunks of three because of three sets of images in LAB color space\n",
    "    for i in range (0, album_length, 3):\n",
    "        yield image_data[i:i+3]\n",
    "\n",
    "\n",
    "class SplitLab(object):\n",
    "    \"\"\"Splits tensor LAB image to L and ab channels.\"\"\"\n",
    "    def __call__(self, image):\n",
    "        L  = image[:1,:,:]\n",
    "        ab = image[1:,:,:]\n",
    "        return (L, ab)\n",
    "    \n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "       Custom dataset for LAB image preprocessing for colorization\n",
    "    \"\"\"\n",
    "    def __init__(self, images):\n",
    "       \"\"\"\n",
    "       images: array of lab images [idx, h, w, channels],\n",
    "       where for channels 0 = L, 1 = a, 2 = b.\n",
    "       \"\"\"\n",
    "       self.images = images\n",
    "       self.composed = T.Compose([T.ToPILImage(),T.ToTensor(),SplitLab])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "      \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        returns L, ab mean, and ab for visualization\n",
    "        \"\"\"\n",
    "        image = self.images[idx, :, :, :]\n",
    "        L, ab = self.composed(image)\n",
    "\n",
    "        a_mean = torch.mean(ab[0, :, :])\n",
    "        b_mean = torch.mean(ab[1, :, :])\n",
    "\n",
    "        sample = {'L': L, 'ab': ab, 'a_mean': a_mean, 'b_mean': b_mean}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = os.getcwd() \n",
    "#change this parameter depending on which album you want\n",
    "target_album = 'LAB_TEST_FACES'\n",
    "batch_size = 32\n",
    "\n",
    "# load in data and split into test and train sets\n",
    "image_data = np.asarray(load(home_dir + '/' + target_album + '/' + '*.jpg'))\n",
    "train_images, test_images = train_test_split(image_data, test_size = 0.1, random_state=42)\n",
    "\n",
    "# dataset and dataloader to prepare images for training\n",
    "train_dataset = ImageDataset(train_images)\n",
    "test_dataset = ImageDataset(test_images)\n",
    "\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# select GPU / CPU\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChrominanceReg(\n",
      "  (mod1): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
      "  )\n",
      "  (mod2): Sequential(\n",
      "    (0): Conv2d(6, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
      "  )\n",
      "  (mod3): Sequential(\n",
      "    (0): Conv2d(12, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
      "  )\n",
      "  (mod4): Sequential(\n",
      "    (0): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
      "  )\n",
      "  (mod5): Sequential(\n",
      "    (0): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
      "  )\n",
      "  (mod6): Sequential(\n",
      "    (0): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): AvgPool2d(kernel_size=(1, 1), stride=1, padding=0)\n",
      "  )\n",
      "  (mod7): Sequential(\n",
      "    (0): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): Flatten(start_dim=1, end_dim=-1)\n",
      "    (3): Linear(in_features=1, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class ChrominanceReg(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ChrominanceReg, self).__init__()\n",
    "        \n",
    "        #128x128\n",
    "        self.mod1 = nn.Sequential(\n",
    "             nn.Conv2d(3, 6, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.AvgPool2d(kernel_size = (1,1), stride = 1)\n",
    "             )\n",
    "        #64x64\n",
    "        self.mod2 = nn.Sequential(\n",
    "             nn.Conv2d(6, 12, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.AvgPool2d(kernel_size = (1,1), stride = 1)\n",
    "             )\n",
    "        #32x32\n",
    "        self.mod3 = nn.Sequential(\n",
    "             nn.Conv2d(12, 24, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.AvgPool2d(kernel_size = (1,1), stride = 1)\n",
    "             )\n",
    "        #16x16\n",
    "        self.mod4 = nn.Sequential(\n",
    "             nn.Conv2d(24, 48, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.AvgPool2d(kernel_size = (1,1), stride = 1)\n",
    "             )\n",
    "        #8x8\n",
    "        self.mod5 = nn.Sequential(\n",
    "             nn.Conv2d(48, 96, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.AvgPool2d(kernel_size = (1,1), stride = 1)\n",
    "             )\n",
    "        #4x4\n",
    "        self.mod6 = nn.Sequential(\n",
    "             nn.Conv2d(96, 192, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.AvgPool2d(kernel_size = (1,1), stride = 1)\n",
    "             )\n",
    "        #2x2\n",
    "        self.mod7 = nn.Sequential(\n",
    "          \n",
    "             nn.Conv2d(192, 384, kernel_size = 3, stride = 2, padding = 1),\n",
    "             nn.ReLU(),\n",
    "             nn.Flatten(),\n",
    "             nn.Linear(1,2)\n",
    "             )\n",
    "        \n",
    "    def forward(self, x):\n",
    "     #    #Normalize input first\n",
    "     #    make_Tensor = T.ToTensor()\n",
    "     # #   transform_pil = T.ToPILImage()\n",
    "       \n",
    "     #    out = make_Tensor(x)\n",
    "     #    #out = transform_pil(x)\n",
    "     #    out = normalize(out)\n",
    "        out = self.mod1(x)\n",
    "        out = self.mod2(out)\n",
    "        out = self.mod3(out)\n",
    "        out = self.mod4(out)\n",
    "        out = self.mod5(out)\n",
    "        out = self.mod6(out)\n",
    "        out = self.mod7(out)\n",
    "        out = torch.mean(out,0, True)\n",
    "        return out\n",
    "\n",
    "\n",
    "regressor = ChrominanceReg().to(device)\n",
    "print(regressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "lr = 0.01\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(regressor.parameters(), lr)\n",
    "\n",
    "regressor.train()\n",
    "\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        # get data\n",
    "        L = data['L']\n",
    "        a_mean = data['a_mean']\n",
    "        b_mean = data['b_mean']\n",
    "\n",
    "        # send to device\n",
    "        L = L.to(device)\n",
    "        a_mean = a_mean.to(device)\n",
    "        b_mean = b_mean.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = regressor(L)\n",
    "        loss = loss_fn(outputs[0], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(epoch, running_loss/len(train_loader)))\n",
    "\n",
    "    if epoch == 30 or epoch == 27 or epoch == 25:\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            regressor.eval()\n",
    "            correct, total = 0, 0\n",
    "            for data in test_loader:\n",
    "                outputs = regressor(data['L'].to(device))\n",
    "                _, prediction = torch.max(outputs[0], 1)\n",
    "                y_pred.extend(prediction.cpu()) # Save Prediction\n",
    "                y_true.extend(data['label']) # Save Truth\n",
    "                for i in range(len(data['label'])):\n",
    "                    # print(prediction[i].cpu(), data['label'][i])\n",
    "                    if(prediction[i]==data['label'][i]):\n",
    "                        correct += 1\n",
    "                    total += 1\n",
    "\n",
    "        print(\"Number Of Images Tested =\", total)\n",
    "        print(\"\\nModel Accuracy =\", (correct/total))\n",
    "print(\"\\nTraining Finished. \\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('ML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12347ee61ea2ffef8bdd924564b209dba478b26ce284a1f8bfda94c61015ebbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
